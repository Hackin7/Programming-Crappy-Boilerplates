# -*- coding: utf-8 -*-

### Work in Progress ###############################
"""Face_generation.ipynb

Automatically generated by Colaboratory.

Original file is located at
    https://colab.research.google.com/drive/1-gKEQksMBzwq59Rr7UXReGUH7q7eDoSL

https://colab.research.google.com/drive/1-gKEQksMBzwq59Rr7UXReGUH7q7eDoSL
"""

import os
os.system("cd /tmp && wget https://data.vision.ee.ethz.ch/cvl/rrothe/imdb-wiki/static/wiki_crop.tar && tar xf wiki_crop.tar")

# Commented out IPython magic to ensure Python compatibility.
import numpy as np
from keras.datasets import mnist
from keras.layers import Input, Dense, Reshape, Flatten, Dropout
from keras.layers import BatchNormalization
from keras.layers.advanced_activations import LeakyReLU
from keras.models import Sequential
from keras.optimizers import Adam
import matplotlib.pyplot as plt
# %matplotlib inline
plt.switch_backend('agg')

from logger import logger

# Commented out IPython magic to ensure Python compatibility.
import numpy as np
from keras.datasets import mnist
from keras.layers import Input, Dense, Reshape, Flatten, Dropout
from keras.layers import BatchNormalization
from keras.layers.advanced_activations import LeakyReLU
from keras.models import Sequential
from keras.optimizers import Adam
import matplotlib.pyplot as plt
# %matplotlib inline
plt.switch_backend('agg')

from keras.models import Sequential
from keras.layers import Dense
from keras.layers import Reshape
from keras.layers.core import Activation
from keras.layers.normalization import BatchNormalization
from keras.layers.convolutional import UpSampling2D
from keras.layers.convolutional import Conv2D, MaxPooling2D
from keras.layers.core import Flatten
from keras.optimizers import SGD
from keras.datasets import mnist
import numpy as np
from PIL import Image
import argparse
import math

def generator():
    model = Sequential()
    model.add(Dense(input_dim=100, output_dim=1024))
    model.add(Activation('tanh'))
    model.add(Dense(128*7*7))
    model.add(BatchNormalization())
    model.add(Activation('tanh'))
    model.add(Reshape((7, 7, 128), input_shape=(128*7*7,)))
    model.add(UpSampling2D(size=(2, 2)))
    model.add(Conv2D(64, (5, 5), padding='same'))
    model.add(Activation('tanh'))
    model.add(UpSampling2D(size=(2, 2)))
    model.add(Conv2D(32, (5, 5), padding='same'))
    model.add(Activation('tanh'))
    model.add(Conv2D(16, (5, 5), padding='same'))
    model.add(Activation('tanh'))
    model.add(UpSampling2D(size=(2, 2)))
    model.add(Conv2D(3, (5, 5), padding='same'))
    model.add(Activation('tanh'))
    return model


def discriminator():
    model = Sequential()
    model.add(
            Conv2D(64, (5, 5),
            padding='same',
            input_shape=(56, 56, 3))
            )
    model.add(Activation('tanh'))
    model.add(MaxPooling2D(pool_size=(2, 2)))
    model.add(Conv2D(128, (5, 5)))
    model.add(Activation('tanh'))
    model.add(MaxPooling2D(pool_size=(2, 2)))
    model.add(Flatten())
    model.add(Dense(1024))
    model.add(Activation('tanh'))
    model.add(Dense(1))
    model.add(Activation('sigmoid'))
    return model

def stacked_generator_discriminator(D, G):
    D.trainable = False
    model = Sequential()
    model.add(G)
    model.add(D)
    return model

def plot_images(samples=16, step=0):
    noise = np.random.normal(0, 1, (samples, 100))
    images = deprocess(Generator.predict(noise))
    plt.figure(figsize=(5, 5))

    for i in range(images.shape[0]):
        plt.subplot(4, 4, i + 1)
        image = images[i, :, :, :]
        image = np.reshape(image, [56, 56,3])
        plt.imshow(image, cmap='gray')
        plt.axis('off')
    plt.tight_layout()
    plt.show()
    #plt.close('all')

from glob import glob
import numpy as np
filenames = np.array(glob('/content/wiki_crop/*/*.jpg')) # Path to the folder that contains jpg files

len(filenames)

# Commented out IPython magic to ensure Python compatibility.
import matplotlib.pyplot as plt
# %matplotlib inline
plt.figure(figsize=(10, 8))
for i in range(20):
    img = plt.imread(filenames[i])
    plt.subplot(4, 5, i+1)
    plt.imshow(img)
    plt.title(img.shape)
    plt.xticks([])
    plt.yticks([])
plt.tight_layout()
plt.show()

import cv2
def load_image(filename, size=(56, 56)):
    img = plt.imread(filename)
    # crop
    rows, cols = img.shape[:2]
#     crop_r, crop_c = 150, 150
#     start_row, start_col = (rows - crop_r) // 2, (cols - crop_c) // 2
#     end_row, end_col = rows - start_row, cols - start_row
#     img = img[start_row:end_row, start_col:end_col, :]
    # resize
    img = cv2.resize(img, size)
    return img

img.shape

plt.figure(figsize=(5, 4))
for i in range(20):
    img = load_image(filenames[i])
    plt.subplot(4, 5, i+1)
    plt.imshow(img)
    plt.xticks([])
    plt.yticks([])
plt.tight_layout()
plt.show()

def preprocess(x):
    return (x/255)*2-1

def deprocess(x):
    return np.uint8((x+1)/2*255)

def plot_images(samples=16, step=0):
    #filename = "mnist_%d.png" % step
    noise = np.random.normal(0, 1, (samples, 100))
    images = deprocess(Generator.predict(noise))
    images = np.clip(images, 0, 255)
    plt.figure(figsize=(10, 10))

    for i in range(images.shape[0]):
        plt.subplot(4, 4, i + 1)
        image = images[i, :, :, :]
        image = np.reshape(image, [56, 56,3])
        plt.imshow(image, cmap='gray')
        plt.axis('off')
    plt.tight_layout()
    plt.show()
    #plt.close('all')

from keras.optimizers import RMSprop, SGD, Adam

Generator = generator()
Generator.compile(loss='binary_crossentropy', optimizer=Adam(lr=0.0002, beta_1=0.5, decay=8e-8))

Discriminator = discriminator()
Discriminator.compile(loss='binary_crossentropy', optimizer=Adam(lr=0.0002, beta_1=0.5, decay=8e-8),metrics=['accuracy'])

Discriminator.summary()

stacked_generator_discriminator = stacked_generator_discriminator(Discriminator, Generator)
stacked_generator_discriminator.compile(loss='binary_crossentropy', optimizer=Adam(lr=0.0002, beta_1=0.5, decay=8e-8))

len(filenames)

X_train = []
for i in range(len(filenames)):
  img = preprocess(load_image(filenames[i]))
  if(len(img.shape)==3):
    X_train.append(img)
len(X_train)

X_train = np.array(X_train)
X_train.shape

save_interval = 1000
batch = 32

stacked_generator_discriminator.summary()

np.max(X_train)

# Commented out IPython magic to ensure Python compatibility.
# %matplotlib inline
disc_loss = []
gen_loss = []
for cnt in range(10000):

  random_index = np.random.randint(0, len(X_train) - batch / 2)
  legit_images = X_train[random_index: random_index + batch // 2].reshape(batch // 2, 56, 56, 3)
  gen_noise = np.random.normal(0, 1, (batch // 2, 100))
  syntetic_images = Generator.predict(gen_noise)

  x_combined_batch = np.concatenate((legit_images, syntetic_images))
  y_combined_batch = np.concatenate((np.ones((batch // 2, 1)), np.zeros((batch // 2, 1))))

  d_loss = Discriminator.train_on_batch(x_combined_batch, y_combined_batch)

  noise = np.random.normal(0, 1, (batch*2, 100))
  y_mislabled = np.ones((batch*2, 1))

  g_loss = stacked_generator_discriminator.train_on_batch(noise, y_mislabled)

  logger.info('epoch: {}, [Discriminator: {}], [Generator: {}]'.format(cnt, d_loss[0], g_loss))
  disc_loss.append(d_loss[0])
  gen_loss.append(g_loss)
  if cnt % save_interval == 0:
      plot_images(step=cnt)

# Commented out IPython magic to ensure Python compatibility.
import matplotlib.ticker as mtick
import matplotlib.pyplot as plt
# %matplotlib inline
epochs = range(1, 10001)
plt.plot(epochs, disc_loss, 'bo', label='Discriminator loss')
plt.plot(epochs, gen_loss, 'r', label='Generator loss')
plt.title('Generator and Discriminator loss values')
plt.xlabel('Epochs')
plt.ylabel('Loss')
plt.legend()
plt.grid('off')
plt.show()

syntetic_images.shape

############################################################################
"""# Vector arithmetic on faces"""

gen_noise = np.random.normal(0, 1, (1, 100))

syntetic_images = Generator.predict(gen_noise)
plt.imshow(deprocess(syntetic_images)[0])
plt.axis('off')
plt.title('Image 1')

gen_noise2 = np.random.normal(0, 1, (1, 100))

syntetic_images = Generator.predict(gen_noise2)
plt.imshow(deprocess(syntetic_images)[0])
plt.axis('off')
plt.title('Image 2')
plt.show()

plt.figure(figsize=(10, 8))
for i in range(10):
  gen_noise3 = gen_noise + (gen_noise2 - gen_noise)*(i+1)/10
  syntetic_images = Generator.predict(gen_noise3)
  plt.subplot(1, 10, i+1)
  plt.imshow(deprocess(syntetic_images)[0])
  plt.title(i+1)
  plt.axis('off')

gen_noise3 = np.random.normal(0, 1, (1, 100))

syntetic_images = Generator.predict(gen_noise3)
plt.imshow(deprocess(syntetic_images)[0])
plt.axis('off')
plt.title('Image 3')
plt.show()

plt.subplot(131)
syntetic_images = Generator.predict(gen_noise)
plt.imshow(deprocess(syntetic_images)[0])
plt.axis('off')
plt.title('Image 1')
plt.subplot(132)
syntetic_images = Generator.predict(gen_noise2)
plt.imshow(deprocess(syntetic_images)[0])
plt.axis('off')
plt.title('Image 2')
plt.subplot(133)
syntetic_images = Generator.predict(gen_noise3)
plt.imshow(deprocess(syntetic_images)[0])
plt.axis('off')
plt.title('Image 3')

gen_noise4 = gen_noise + gen_noise2 - gen_noise3

syntetic_images = Generator.predict(gen_noise4)
plt.imshow(deprocess(syntetic_images)[0])
plt.axis('off')
plt.title('Image 4')
plt.show()
